{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfed75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "from datasets import Dataset\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "#CHECK ACCURACY OF THE LANGUAGE TAGS COMPARING WITH THE CLASSIFICATION OF GPT-4.1-MINI\n",
    "\n",
    "#API config\n",
    "load_dotenv(\"key.env\")\n",
    "api_key = os.getenv(\"OPENAI_TOKEN\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "test_corpus = Dataset.from_parquet(\"test_randomsplit.parquet\") #generated with create_corpus.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count conversations of each language\n",
    "language_counts = Counter(test_corpus['language'])\n",
    "\n",
    "#obtain the 20 most common languages in the corpus\n",
    "top_20_languages = [lang for lang, _ in language_counts.most_common(20)]\n",
    "\n",
    "#print the top 20 languages in order\n",
    "print(\"Top 20 most common languages:\")\n",
    "for i, lang in enumerate(top_20_languages, 1):\n",
    "    print(f\"{i}. {lang} ({language_counts[lang]} conversations)\")\n",
    "\n",
    "#convert to dataframe\n",
    "df = test_corpus.to_pandas()\n",
    "\n",
    "#extract 100 random conversations of each of the 20 most common languages\n",
    "df_top_20 = df[df['language'].isin(top_20_languages)]\n",
    "df_balanced = df_top_20.groupby('language', group_keys=False).apply(lambda x: x.sample(n=min(len(x), 100), random_state=42))\n",
    "\n",
    "#convert to dataset\n",
    "balanced_dataset = Dataset.from_pandas(df_balanced.reset_index(drop=True))\n",
    "\n",
    "#save the conversations\n",
    "balanced_dataset.to_parquet(\"balanced_top20_100each.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset with 100 conversations of each of the top 20 languages\n",
    "dataset = Dataset.from_parquet(\"balanced_top20_100each.parquet\")\n",
    "\n",
    "#prepare csv files to save results\n",
    "output_file = \"gpt_language_identification_all.csv\" #save the results of the inference \n",
    "metrics_file = \"language_accuracy_metrics.csv\" #metric of accuracy for the 20 languages\n",
    "\n",
    "#counters for each language\n",
    "counts = defaultdict(int) #total examples per language     \n",
    "corrects = defaultdict(int) #conversations whose language tag agrees with the classification of GPT-4.1-mini\n",
    "\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow([\"language\", \"conversation\", \"answer_gpt\", \"correct\"]) #fields for the csv \"gpt_language_identification_all.csv\"\n",
    "    \n",
    "    #iterate the dataset\n",
    "    for example in dataset:\n",
    "        gold_language = example[\"language\"]\n",
    "        if gold_language == \"unknown\": #one of the 20 most common tags is \"unknown\": we skip that one\n",
    "            continue\n",
    "        conversation  = example[\"conversation\"]\n",
    "        \n",
    "        #API call\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"gpt-4.1-mini-2025-04-14\", \n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that identifies the language of a conversation.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"What language is this conversation written in? Answer with only one word, and write the name of the language in English (e.g., French, Vietnamese, Spanish):\\n\\n{conversation}\"}\n",
    "\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            answer = resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            answer = f\"ERROR: {e}\"\n",
    "        \n",
    "        #compare tags (ignore upper case letters)\n",
    "        is_correct = (answer.lower() == gold_language.lower()) #bool\n",
    "        \n",
    "        #update counters\n",
    "        counts[gold_language]   += 1\n",
    "        corrects[gold_language] += int(is_correct)\n",
    "        \n",
    "        #write the result of the API call\n",
    "        writer.writerow([gold_language, conversation, answer, is_correct])\n",
    "\n",
    "#calculate and save metrics\n",
    "with open(metrics_file, mode='w', newline='', encoding='utf-8') as f_met:\n",
    "    writer = csv.writer(f_met)\n",
    "    writer.writerow([\"language\", \"total\", \"correct\", \"accuracy\"])\n",
    "    for lang in sorted(counts):\n",
    "        total   = counts[lang]\n",
    "        corr    = corrects[lang]\n",
    "        acc     = corr / total if total > 0 else 0.0\n",
    "        writer.writerow([lang, total, corr, f\"{acc:.2%}\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
